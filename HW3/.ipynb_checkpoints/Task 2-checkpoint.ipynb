{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import nltk\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from collections import defaultdict, OrderedDict\n",
    "from nltk import tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "import gzip\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def readJson(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return df\n",
    "\n",
    "df = readJson('assignment1/train.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalData = [df[x] for x in range(0,200000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.random.seed(1)\n",
    "# np.random.shuffle(df)\n",
    "trainingData = [df[x] for x in range(0,200000)]\n",
    "validationData = [df[x] for x in range(100000,200000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userIndex = {}\n",
    "users = []\n",
    "userToItem = defaultdict(list)\n",
    "itemIndex = {}\n",
    "items = []\n",
    "itemToUser = defaultdict(list)\n",
    "i,j = 0,0\n",
    "for data in trainingData:\n",
    "    userToItem[data['reviewerID']].append(data['itemID'])\n",
    "    itemToUser[data['itemID']].append(data['reviewerID'])\n",
    "    if data['reviewerID'] not in userIndex:\n",
    "        userIndex[data['reviewerID']] = i\n",
    "        users.append(data['reviewerID'])\n",
    "        i += 1\n",
    "    if data['itemID'] not in itemIndex:\n",
    "        itemIndex[data['itemID']] = j\n",
    "        items.append(data['itemID'])\n",
    "        j += 1\n",
    "userItemNum = defaultdict(int)\n",
    "for user in userToItem:\n",
    "    userItemNum[user] = len(userToItem[user])\n",
    "Rui = np.zeros((len(users), len(items)))\n",
    "for data in trainingData:\n",
    "    Rui[userIndex[data['reviewerID']]][itemIndex[data['itemID']]] = data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "user_sorted = list(sorted(userItemNum, key = lambda x : userItemNum[x], reverse = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# validationPredictions = []\n",
    "# validationRatings = []\n",
    "# for data in validationData:\n",
    "#     u,i = data['reviewerID'], data['itemID']\n",
    "#     prediction = []\n",
    "#     if u in userAverageRating:\n",
    "#         prediction.append(userAverageRating[u])      \n",
    "#     if i in itemAverageRating:\n",
    "#         prediction.append(itemAverageRating[i])\n",
    "#     elif u not in userAverageRating:\n",
    "#         prediction.append(globalAverageRating)\n",
    "#     validationPredictions.append(np.mean(prediction))\n",
    "#     validationRatings.append(data['rating'])\n",
    "# mean_squared_error(validationPredictions, validationRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradientDescent(weight_u, weight_1, regularization =1):\n",
    "    alpha = random.random()\n",
    "    np.random.seed(0)\n",
    "    beta_u = np.random.rand(len(userIndex.keys()))\n",
    "    beta_i = np.random.rand(len(itemIndex.keys()))\n",
    "#     beta_u = np.ones(len(userIndex.keys()))\n",
    "#     beta_i = np.ones(len(itemIndex.keys()))\n",
    "    maxIter = 1e5\n",
    "    numIter = 0\n",
    "    alpha_path = []\n",
    "    beta_u_path = []\n",
    "    beta_i_path = []\n",
    "    trainingMSE_path = []\n",
    "    validationMSE_path = []\n",
    "    while numIter < maxIter:\n",
    "        alpha = np.sum([data['rating'] - weight_u*beta_u[userIndex[data['reviewerID']]] - \\\n",
    "                        weight_i*beta_i[itemIndex[data['itemID']]] for data in trainingData]) / len(trainingData)\n",
    "        beta_u = np.array([np.sum([Rui[userIndex[user]][itemIndex[item]] - alpha - \\\n",
    "                                   weight_i*beta_i[itemIndex[item]] for item in userToItem[user]])\n",
    "                  /(regularization + len(userToItem[user])) for user in users])\n",
    "        beta_i = np.array([np.sum([Rui[userIndex[user]][itemIndex[item]] - alpha - \\\n",
    "                                   weight_u*beta_u[userIndex[user]] for user in itemToUser[item]])\n",
    "                  /(regularization + len(itemToUser[item])) for item in items])\n",
    "\n",
    "        trainingMSE = mean_squared_error([alpha + beta_u[userIndex[data['reviewerID']]] + \\\n",
    "                        beta_i[itemIndex[data['itemID']]] for data in trainingData], \\\n",
    "                                        [data['rating'] for data in trainingData])\n",
    "        # Calculate validation MSE\n",
    "#         prediction = np.zeros(len(validationData)) + alpha\n",
    "#         i = 0\n",
    "#         for data in validationData:\n",
    "#             if data['reviewerID'] in userIndex:\n",
    "#                 prediction[i] += beta_u[userIndex[data['reviewerID']]]\n",
    "#             if data['itemID'] in itemIndex:\n",
    "#                 prediction[i] += beta_i[itemIndex[data['itemID']]]\n",
    "#             i += 1\n",
    "#         validationMSE = mean_squared_error(prediction, [data['rating'] for data in validationData])\n",
    "        validationMSE = trainingMSE + regularization*(np.sum(beta_u**2) + np.sum(beta_i**2))/len(trainingData)\n",
    "        \n",
    "        numIter += 1 \n",
    "        trainingMSE_path.append(trainingMSE)\n",
    "        validationMSE_path.append(validationMSE)\n",
    "        alpha_path.append(alpha)\n",
    "        beta_u_path.append(beta_u)\n",
    "        beta_i_path.append(beta_i)\n",
    "        if numIter % 20 == 0:\n",
    "            print trainingMSE, validationMSE\n",
    "        if len(validationMSE_path) >= 6 and validationMSE_path[-5] <= validationMSE_path[-4] <= \\\n",
    "            validationMSE_path[-3] <= validationMSE_path[-2] <= validationMSE_path[-1]:\n",
    "            print 'Iteration:', numIter, 'Training MSE =', trainingMSE_path[-5], \\\n",
    "                  ', Validation MSE =', validationMSE_path[-5]\n",
    "                \n",
    "            return alpha_path[-5], beta_u_path[-5], beta_i_path[-5], trainingMSE_path[-5], validationMSE_path[-5]\n",
    "\n",
    "    return alpha, beta_u, beta_i, trainingMSE, validationMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 17 Training MSE = 0.808150448501 , Validation MSE = 0.932087474461\n"
     ]
    }
   ],
   "source": [
    "alpha, beta_u, beta_i, trainingMSE, validationMSE = gradientDescent( 1, 1,regularization = 5.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = open(\"assignment1/predictions_Rating.txt\", 'w')\n",
    "for l in open(\"assignment1/pairs_Rating.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    this_beta_u, this_beta_i = 0,0\n",
    "\n",
    "                                         \n",
    "    if u in userIndex:\n",
    "        this_beta_u += 1.13*beta_u[userIndex[u]]\n",
    "    elif i in itemIndex:\n",
    "        this_beta_i += 1.13*beta_i[itemIndex[i]]\n",
    "    if i in itemIndex:\n",
    "        this_beta_i += 0.87*beta_i[itemIndex[i]]\n",
    "    elif u in userIndex:\n",
    "        this_beta_u += 0.87*beta_u[userIndex[u]]\n",
    "    p = alpha + this_beta_u + this_beta_i\n",
    "    if p>5:\n",
    "        p = 5\n",
    "    if p<1:\n",
    "        p = 1\n",
    "    predictions.write(u + '-' + i + ',' + str(p) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = open(\"assignment1/predictions_Rating.txt\", 'w')\n",
    "for l in open(\"assignment1/pairs_Rating.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    this_beta_u, this_beta_i = 0,0\n",
    "    if u in userLevel1:\n",
    "        this_beta_u = beta_u[userIndex[u]]\n",
    "    if i in userLevel2:\n",
    "        this_beta_i = beta_i[itemIndex[i]]\n",
    "    p = alpha + this_beta_u + this_beta_i\n",
    "    if p>5.0:\n",
    "        print 'da',\n",
    "    predictions.write(u + '-' + i + ',' + str(min(p,5)) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradientDescent2(regularization = 1, iniStepSize = 0.01, T = 10, k = 3):\n",
    "    alpha = random.random()\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    beta_u = np.random.rand(len(userIndex.keys()))\n",
    "    beta_i = np.random.rand(len(itemIndex.keys()))\n",
    "    r_u = np.random.rand(len(userIndex.keys()))\n",
    "    r_i = np.random.rand(len(itemIndex.keys()))\n",
    "#     beta_u = np.ones(len(userIndex.keys()))\n",
    "#     beta_i = np.ones(len(itemIndex.keys()))\n",
    "    maxIter = 1e3\n",
    "    numIter = 0\n",
    "    alpha_path = []\n",
    "    beta_u_path = []\n",
    "    beta_i_path = []\n",
    "    r_u_path = []\n",
    "    r_i_path = []\n",
    "    trainingMSE_path = []\n",
    "    validationMSE_path = []\n",
    "    while numIter < maxIter:\n",
    "        print numIter\n",
    "        stepSize = iniStepSize /(1+numIter*1./T)\n",
    "        \n",
    "        alpha = alpha - stepSize*(2*np.sum([alpha + beta_u[userIndex[data['reviewerID']]] + \\\n",
    "                                            beta_i[itemIndex[data['itemID']]] + \\\n",
    "                                            np.dot(r_u[userIndex[data['reviewerID']]], r_i[itemIndex[data['itemID']]].T)\\\n",
    "                                            - data['rating'] \\\n",
    "                                           for data in trainingData]) / len(trainingData) + 2*regularization*alpha)\n",
    "        \n",
    "        beta_u = beta_u - stepSize*(2*np.array([np.mean([alpha + beta_u[userIndex[user]] + beta_i[itemIndex[item]] + \\\n",
    "                                                        np.dot(r_u[userIndex[user]], r_i[itemIndex[item]].T) - \\\n",
    "                                                        Rui[userIndex[user]][itemIndex[item]] for item in userToItem[user]])\\\n",
    "                                                for user in users])  + 2*regularization*beta_u)\n",
    "\n",
    "        beta_i = beta_i - stepSize*(2*np.array([np.mean([alpha + beta_u[userIndex[user]] + beta_i[itemIndex[item]] + \\\n",
    "                                                        np.dot(r_u[userIndex[user]], r_i[itemIndex[item]].T) - \\\n",
    "                                                        Rui[userIndex[user]][itemIndex[item]] for user in itemToUser[item]]) \\\n",
    "                                                for item in items])  + 2*regularization*beta_i)\n",
    "        \n",
    "        r_u = r_u - stepSize*(np.array([np.mean([2*r_i[itemIndex[item]]*\\\n",
    "                                                (alpha+beta_u[userIndex[user]]+beta_i[itemIndex[item]]+\\\n",
    "                                                 np.dot(r_u[userIndex[user]], r_i[itemIndex[item]].T)-\\\n",
    "                                                 Rui[userIndex[user]][itemIndex[item]]) \\\n",
    "                                                for item in userToItem[user]], axis = 0) \\\n",
    "                                        for user in users])\\\n",
    "                              +2*regularization*r_u)\n",
    "        \n",
    "        r_i = r_i - stepSize*(np.array([np.mean([2*r_u[userIndex[user]]*\\\n",
    "                                                (alpha+beta_u[userIndex[user]]+beta_i[itemIndex[item]]+\\\n",
    "                                                 np.dot(r_u[userIndex[user]], r_i[itemIndex[item]].T)-\\\n",
    "                                                 Rui[userIndex[user]][itemIndex[item]]) \\\n",
    "                                                for user in itemToUser[item]], axis = 0) \\\n",
    "                                        for item in items])\\\n",
    "                              +2*regularization*r_i)\n",
    "        \n",
    "        trainingMSE = mean_squared_error([alpha + beta_u[userIndex[data['reviewerID']]] + \\\n",
    "                        beta_i[itemIndex[data['itemID']]] + \\\n",
    "                               np.dot(r_u[userIndex[data['reviewerID']]], r_i[itemIndex[data['itemID']]].T) for data in trainingData], \\\n",
    "                                        [data['rating'] for data in trainingData])\n",
    "        # Calculate validation MSE\n",
    "        prediction = np.zeros(len(validationData)) + alpha\n",
    "        i = 0\n",
    "        for data in validationData:\n",
    "            if data['reviewerID'] in userIndex:\n",
    "                prediction[i] += beta_u[userIndex[data['reviewerID']]]\n",
    "            else:\n",
    "                prediction[i] += np.mean(beta_u)\n",
    "            if data['itemID'] in itemIndex:\n",
    "                prediction[i] += beta_i[itemIndex[data['itemID']]]\n",
    "            else:\n",
    "                prediction[i] += np.mean(beta_i)\n",
    "            if data['reviewerID'] in userIndex and data['itemID'] in itemIndex:\n",
    "                prediction[i] += np.dot(r_u[userIndex[data['reviewerID']]], r_i[itemIndex[data['itemID']]].T)\n",
    "            i += 1\n",
    "        validationMSE = mean_squared_error(prediction, [data['rating'] for data in validationData])\n",
    "        print trainingMSE,validationMSE\n",
    "        numIter += 1 \n",
    "        trainingMSE_path.append(trainingMSE)\n",
    "        validationMSE_path.append(validationMSE)\n",
    "        alpha_path.append(alpha)\n",
    "        beta_u_path.append(beta_u)\n",
    "        beta_i_path.append(beta_i)\n",
    "        r_u_path.append(r_u)\n",
    "        r_i_path.append(r_i)\n",
    "        if len(validationMSE_path) >= 6 and validationMSE_path[-5] <= validationMSE_path[-4] <= \\\n",
    "            validationMSE_path[-3] <= validationMSE_path[-2] <= validationMSE_path[-1]:\n",
    "            print 'Iteration:', numIter, 'Training MSE =', trainingMSE_path[-5], \\\n",
    "                  ', Validation MSE =', validationMSE_path[-5]\n",
    "                \n",
    "            return alpha_path[-5], beta_u_path[-5], beta_i_path[-5], r_u_path[-5], r_i_path[-5], trainingMSE_path[-5], validationMSE_path[-5]\n",
    "\n",
    "    return alpha, beta_u, beta_i, trainingMSE, validationMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha, beta_u, beta_i, r_u, r_i, trainingMSE, validationMSE = \\\n",
    "gradientDescent2(regularization=1, iniStepSize=0.5, T=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
