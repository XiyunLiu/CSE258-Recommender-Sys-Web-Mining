{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE258 HW 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib\n",
    "import string\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "from collections import defaultdict\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import log10\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseData(fname):\n",
    "    for l in urllib.urlopen(fname):\n",
    "        yield eval(l)\n",
    "\n",
    "print \"Reading data...\"\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))[:5000]\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "The 5 most-frequently-occurring bigrams along with their number of occurrences:\n",
    "\n",
    "The bigram ('with', 'a') has an occurence of 4587\n",
    "\n",
    "The bigram ('in', 'the') has an occurence of 2595\n",
    "\n",
    "The bigram ('of', 'the') has an occurence of 2245\n",
    "\n",
    "The bigram ('is', 'a') has an occurence of 2056\n",
    "\n",
    "The bigram ('on', 'the') has an occurence of 2033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bigram ('with', 'a') has an occurence of 4587\n",
      "The bigram ('in', 'the') has an occurence of 2595\n",
      "The bigram ('of', 'the') has an occurence of 2245\n",
      "The bigram ('is', 'a') has an occurence of 2056\n",
      "The bigram ('on', 'the') has an occurence of 2033\n"
     ]
    }
   ],
   "source": [
    "# bigram count\n",
    "punctuation = set(string.punctuation)\n",
    "bigramCount = defaultdict(int)\n",
    "\n",
    "for d in data:\n",
    "    text = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    bg = list(bigrams(text.split())) # all bigrams in text\n",
    "    for b in bg:\n",
    "        bigramCount[b] += 1\n",
    "# sort \n",
    "bigramSorted = list(sorted(bigramCount, key = lambda x : bigramCount[x], reverse = True))\n",
    "for i in range(0,5):\n",
    "    print 'The bigram ' + str(bigramSorted[i]) + ' has an occurence of ' + str(bigramCount[bigramSorted[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "The MSE obtained using bigrams only is : 0.34361068509441478"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Bigrams = [x for x in bigramSorted[:1000]]\n",
    "bigramID = dict(zip(Bigrams, range(len(Bigrams))))\n",
    "bigramSet = set(Bigrams)\n",
    "\n",
    "def feat(data):\n",
    "    feat = [0] * len(Bigrams)\n",
    "    text = ''.join([c for c in data['review/text'].lower() if not c in punctuation])\n",
    "    bg = list(bigrams(text.split())) # all bigrams in text\n",
    "    for b in bg:\n",
    "        if b in bigramSet:\n",
    "              feat[bigramID[b]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34361068509441478"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [feat(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(x, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(x)\n",
    "\n",
    "mean_squared_error(predictions, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "The MSE obtained using unigrams and bigrams is : 0.28933386918744819"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# unigram count\n",
    "wordCount = defaultdict(int)\n",
    "\n",
    "for d in data:\n",
    "    text = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    for w in text.split():\n",
    "        wordCount[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge unigram and bigram\n",
    "mergeCount = dict(wordCount)\n",
    "mergeCount.update(bigramCount)\n",
    "\n",
    "mergeSorted = list(sorted(mergeCount, key = lambda x : mergeCount[x], reverse = True))\n",
    "\n",
    "grams = [x for x in mergeSorted[:1000]]\n",
    "gramID = dict(zip(grams, range(len(grams))))\n",
    "gramSet = set(grams)\n",
    "\n",
    "def feat(data):\n",
    "    feat = [0] * len(grams)\n",
    "    text = ''.join([c for c in data['review/text'].lower() if not c in punctuation])\n",
    "    bg = list(bigrams(text.split())) # all bigrams in text\n",
    "    for w in text.split() + bg:\n",
    "        if w in gramSet:\n",
    "            feat[gramID[w]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28933386918744819"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [feat(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(x, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(x)\n",
    "\n",
    "mean_squared_error(predictions, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "The 5 unigrams/bigrams with the most positive associated weights are : \n",
    "\n",
    "'wonderful' has associated weight of 0.18422371334\n",
    "\n",
    "'favorite' has associated weight of 0.166412033416\n",
    "\n",
    "'easy' has associated weight of 0.16368451567\n",
    "\n",
    "'refreshing' has associated weight of 0.159867176865\n",
    "\n",
    "'slick' has associated weight of 0.156355669128\n",
    "\n",
    "'The 5 unigrams/bigrams with the most negative associated weights are : \n",
    "\n",
    "'water' has associated weight of -0.256047280155\n",
    "\n",
    "'corn' has associated weight of -0.250891464933\n",
    "\n",
    "'straw' has associated weight of -0.226674462117\n",
    "\n",
    "'yellow' has associated weight of -0.213722070367\n",
    "\n",
    "'watery' has associated weight of -0.201671403238"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 unigrams/bigrams with the most positive associated weights are : \n",
      "sort has associated weight of 0.521680776822\n",
      "('a', 'bad') has associated weight of 0.226288834348\n",
      "('of', 'these') has associated weight of 0.22289001188\n",
      "('not', 'bad') has associated weight of 0.216268615711\n",
      "('the', 'best') has associated weight of 0.213772219036\n",
      "\n",
      " The 5 unigrams/bigrams with the most negative associated weights are : \n",
      "('sort', 'of') has associated weight of -0.645937945334\n",
      "water has associated weight of -0.271900176951\n",
      "corn has associated weight of -0.23756003904\n",
      "('the', 'background') has associated weight of -0.218138672448\n",
      "straw has associated weight of -0.199753548917\n"
     ]
    }
   ],
   "source": [
    "weights = zip(theta[0:-1], range(1000))\n",
    "weights.sort()\n",
    "\n",
    "print 'The 5 unigrams/bigrams with the most positive associated weights are : '\n",
    "for i in range(0,5):\n",
    "    print  str(grams[weights[-i-1][1]]) + ' has associated weight of ' + str(weights[-i-1][0])\n",
    "print '\\n The 5 unigrams/bigrams with the most negative associated weights are : '\n",
    "for i in range(0,5):\n",
    "    print  str(grams[weights[i][1]]) + ' has associated weight of ' + str(weights[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "The inverse document frequency of the words 'foam', 'smell', 'banana', 'lactic', and 'tart' are :\n",
    "\n",
    "[1.1378686206869628, 0.5379016188648442, 1.6777807052660807, 2.9208187539523753, 1.8068754016455384]\n",
    "\n",
    "Their tf-idf scores in the first review (using log base 10) are:\n",
    "\n",
    "[2.2757372413739256,\n",
    " 0.5379016188648442,\n",
    " 3.3555614105321614,\n",
    " 5.841637507904751,\n",
    " 1.8068754016455384]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1378686206869628, 0.5379016188648442, 1.6777807052660807, 2.9208187539523753, 1.8068754016455384]\n"
     ]
    }
   ],
   "source": [
    "wordList = ['foam', 'smell', 'banana', 'lactic', 'tart']\n",
    "N = len(data)\n",
    "# inverse document frequency\n",
    "def idf(w):\n",
    "    count = 0\n",
    "    for d in data:\n",
    "        text = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "        if w in text.split():\n",
    "            count += 1\n",
    "    return log10(N * 1. / count)\n",
    "\n",
    "idfList = [idf(w) for w in wordList]\n",
    "print idfList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# term frequency in first review \n",
    "def tf(w):\n",
    "    count = 0\n",
    "    text = ''.join([c for c in data[0]['review/text'].lower() if not c in punctuation])\n",
    "    for t in text.split():\n",
    "        if t == w:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "tfList = [tf(w) for w in wordList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.2757372413739256,\n",
       " 0.5379016188648442,\n",
       " 3.3555614105321614,\n",
       " 5.841637507904751,\n",
       " 1.8068754016455384]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i * j for i,j in zip(idfList, tfList)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "The cosine similarity between the first and the second review in terms of their tf-idf representations is : 0.10613024167865803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "# tfidf feature words -- 1000 most common\n",
    "featWords = [x[1] for x in counts[:1000]]\n",
    "featID = dict(zip(featWords, range(1000)))\n",
    "\n",
    "# idf for feature words\n",
    "countList = [0] * 1000\n",
    "for d in data:\n",
    "    text = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    textWord = set(text.split())\n",
    "    for t in textWord:\n",
    "        if t in featID:\n",
    "            countList[featID[t]] += 1\n",
    "idfList = [log10(N * 1. / x) for x in countList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tfide feature extraction\n",
    "def tfidfFeat(d):\n",
    "    count = [0] * len(featWords) # tf counts\n",
    "    text = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    for t in text.split():\n",
    "        if t in featWords:\n",
    "            count[featID[t]] += 1\n",
    "    feat = [i * j for i,j in zip(idfList, count)]\n",
    "#     feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10613024167865803"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat1 = tfidfFeat(data[0])\n",
    "feat2 = tfidfFeat(data[1])\n",
    "1 - spatial.distance.cosine(feat1, feat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "beerID : 52211\n",
    "\n",
    "profileName : Dope\n",
    "\n",
    "reviewText : A: A hazy deep orange pour, almost red. Small white head that fades quickly. A little spotty lacing.\t\tS: Big pumpkin, cinnamon, ginger, nutmeg and brown sugar. Sweet. Smells like a pumpkin pie mixed with a gingerbread cookie.\t\tT: Tons of pumpkin dominates throughout. Cinnamon, ginger, nutmeg and a bit of vanilla creaminess. \t\tM: Smooth medium body. Tiny bit of drying alcohol.\t\tO: Excellent pumpkin ale. Heavy on the pumpkin but the spices don't get completely overshadowed either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beerID : 52211\n",
      "profileName : Dope\n",
      "\n",
      "reviewText : A: A hazy deep orange pour, almost red. Small white head that fades quickly. A little spotty lacing.\t\tS: Big pumpkin, cinnamon, ginger, nutmeg and brown sugar. Sweet. Smells like a pumpkin pie mixed with a gingerbread cookie.\t\tT: Tons of pumpkin dominates throughout. Cinnamon, ginger, nutmeg and a bit of vanilla creaminess. \t\tM: Smooth medium body. Tiny bit of drying alcohol.\t\tO: Excellent pumpkin ale. Heavy on the pumpkin but the spices don't get completely overshadowed either.\n"
     ]
    }
   ],
   "source": [
    "cosineList = [1 - spatial.distance.cosine(feat1, tfidfFeat(x)) for x in data[1:]]\n",
    "result = zip(cosineList, range(len(cosineList)))\n",
    "result.sort()\n",
    "result.reverse()\n",
    "print 'beerID : ' + str(data[result[0][1]]['beer/beerId']) + '\\n' + 'profileName : ' + str(data[result[0][1]]['user/profileName']) + '\\n'\n",
    "print 'reviewText : ' + data[result[0][1]]['review/text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8\n",
    "The MSE obtained with the 1000-dimensional tf-idf representations is : 0.27875956007772285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rewrite the tfide feature extraction with offset\n",
    "def tfidfFeat(d):\n",
    "    count = [0] * len(featWords) # tf counts\n",
    "    text = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    for t in text.split():\n",
    "        if t in featWords:\n",
    "            count[featID[t]] += 1\n",
    "    feat = [i * j for i,j in zip(idfList, count)]\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27875956007772285"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [tfidfFeat(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(x, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(x)\n",
    "\n",
    "mean_squared_error(predictions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
