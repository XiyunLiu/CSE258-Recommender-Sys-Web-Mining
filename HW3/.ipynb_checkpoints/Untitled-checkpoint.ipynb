{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from collections import defaultdict, OrderedDict\n",
    "from nltk import tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "import gzip\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def readJson(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return df\n",
    "\n",
    "df = readJson('assignment1/train.json.gz')\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(df)\n",
    "\n",
    "trainingData = [df[x] for x in range(0,150000)]\n",
    "validationData = [df[x] for x in range(150000,200000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userIndex = {}\n",
    "users = []\n",
    "userToItem = defaultdict(list)\n",
    "itemIndex = {}\n",
    "items = []\n",
    "itemToUser = defaultdict(list)\n",
    "i,j = 0,0\n",
    "trainLines,validationLines = [],[]\n",
    "ID = 0\n",
    "for data in trainingData:\n",
    "    userToItem[data['reviewerID']].append(data['itemID'])\n",
    "    itemToUser[data['itemID']].append(data['reviewerID'])\n",
    "    if data['reviewerID'] not in userIndex:\n",
    "        userIndex[data['reviewerID']] = i\n",
    "        users.append(data['reviewerID'])\n",
    "        i += 1\n",
    "    if data['itemID'] not in itemIndex:\n",
    "        itemIndex[data['itemID']] = j\n",
    "        items.append(data['itemID'])\n",
    "        j += 1\n",
    "    trainLines.append(str(ID)+','+str(userIndex[data['reviewerID']])+','+str(itemIndex[data['itemID']])+','+str(int(data['rating'])))\n",
    "    ID += 1\n",
    "\n",
    "for data in validationData:\n",
    "    userToItem[data['reviewerID']].append(data['itemID'])\n",
    "    itemToUser[data['itemID']].append(data['reviewerID'])\n",
    "    if data['reviewerID'] not in userIndex:\n",
    "        userIndex[data['reviewerID']] = i\n",
    "        users.append(data['reviewerID'])\n",
    "        i += 1\n",
    "    if data['itemID'] not in itemIndex:\n",
    "        itemIndex[data['itemID']] = j\n",
    "        items.append(data['itemID'])\n",
    "        j += 1\n",
    "    validationLines.append(str(ID)+','+str(userIndex[data['reviewerID']])+','+str(itemIndex[data['itemID']]))\n",
    "    ID += 1\n",
    "\n",
    "# Rui = np.zeros((len(users), len(items)))\n",
    "# for data in trainingData:\n",
    "#     Rui[userIndex[data['reviewerID']]][itemIndex[data['itemID']]] = data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.txt', mode='wt') as myfile:\n",
    "    myfile.write('ID,user,movie,rating\\n')\n",
    "    myfile.write('\\n'.join(trainLines))\n",
    "with open('validation.txt', mode='wt') as myfile:\n",
    "    myfile.write('ID,user,movie,rating\\n')\n",
    "    myfile.write('\\n'.join(validationLines ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "pd.options.display.max_columns = 10 \n",
    "pd.options.display.width = 134\n",
    "pd.options.display.max_rows = 20\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "train = pd.read_csv('train.txt')\n",
    "test = pd.read_csv('validation.txt')\n",
    "matrix = pd.concat([train,test]).pivot('user','movie','rating')\n",
    "movie_means = matrix.mean()\n",
    "user_means = matrix.mean(axis=1)\n",
    "mzm = matrix-movie_means\n",
    "# mz = mzm.fillna(0)\n",
    "# mask = -mzm.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mz = mzm.fillna(0)\n",
    "mask = -mzm.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here here2 1 0.00019 998.99981\n"
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "mse_last = 999\n",
    "while iteration<10:\n",
    "    iteration += 1\n",
    "    svd = TruncatedSVD(n_components=15,random_state=42)\n",
    "    svd.fit(mz)\n",
    "    print 'here',\n",
    "    mzsvd = pd.DataFrame(svd.inverse_transform(svd.transform(mz)),columns=mz.columns,index=mz.index)\n",
    "    print 'here2',\n",
    "#     mse = mean_squared_error(mzsvd[mask].fillna(0),mzm[mask].fillna(0))\n",
    "#     print('%i %.5f %.5f'%(iteration,mse,mse_last-mse))\n",
    "    mzsvd[mask] = mzm[mask]\n",
    "\n",
    "    mz = mzsvd\n",
    "#     if mse_last-mse<0.00001: break\n",
    "#     mse_last = mse\n",
    "\n",
    "# m = mz+movie_means\n",
    "# m = m.clip(lower=1,upper=5)\n",
    "\n",
    "# test['rating'] = test.apply(lambda x:m[m.index==x.user][x.movie].values[0],axis=1)\n",
    "\n",
    "# # There are some movies who did not have enough info to make prediction, so just used average value for user\n",
    "# missing = np.where(test.rating.isnull())[0]\n",
    "# test.ix[missing,'rating'] = user_means[test.loc[missing].user].values\n",
    "\n",
    "# test.to_csv('submission.csv',index=False,columns=['ID','rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in open(\"assignment1/pairs_Rating.txt\"):\n",
    "    if line.startswith(\"userID\"):\n",
    "        continue\n",
    "    user,item = line.strip().split('-')\n",
    "    if user not in userIndex:\n",
    "        userIndex[user] = i\n",
    "        i += 1\n",
    "    if item not in itemIndex:\n",
    "        itemIndex[item] = j\n",
    "    lines.append(str(userIndex[user])+','+ str(itemIndex[item]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
