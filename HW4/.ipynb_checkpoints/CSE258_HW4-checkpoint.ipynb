{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib\n",
    "import string\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import spatial\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseData(fname):\n",
    "    for l in urllib.urlopen(fname):\n",
    "        yield eval(l)\n",
    "\n",
    "print \"Reading data...\"\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))[:5000]\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beer/ABV': 5.0,\n",
       " 'beer/beerId': '47986',\n",
       " 'beer/brewerId': '10325',\n",
       " 'beer/name': 'Sausa Weizen',\n",
       " 'beer/style': 'Hefeweizen',\n",
       " 'review/appearance': 2.5,\n",
       " 'review/aroma': 2.0,\n",
       " 'review/overall': 1.5,\n",
       " 'review/palate': 1.5,\n",
       " 'review/taste': 1.5,\n",
       " 'review/text': 'A lot of foam. But a lot.\\tIn the smell some banana, and then lactic and tart. Not a good start.\\tQuite dark orange in color, with a lively carbonation (now visible, under the foam).\\tAgain tending to lactic sourness.\\tSame for the taste. With some yeast and banana.',\n",
       " 'review/timeStruct': {'hour': 20,\n",
       "  'isdst': 0,\n",
       "  'mday': 16,\n",
       "  'min': 57,\n",
       "  'mon': 2,\n",
       "  'sec': 3,\n",
       "  'wday': 0,\n",
       "  'yday': 47,\n",
       "  'year': 2009},\n",
       " 'review/timeUnix': 1234817823,\n",
       " 'user/profileName': 'stcules'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "The number of unique bigram is 182246\n",
    "\n",
    "The 5 most-frequently-occurring bigrams along with their number of occurrences in the corpus:\n",
    "\n",
    "('with', 'a') : 4587\n",
    "\n",
    "('in', 'the') : 2595\n",
    "\n",
    "('of', 'the') : 2245\n",
    "\n",
    "('is', 'a') : 2056\n",
    "\n",
    "('on', 'the') : 2033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "print punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram = defaultdict(int)\n",
    "allText = [x['review/text'] for x in data]\n",
    "for text in allText:\n",
    "    textList = text.translate(None, punctuation).lower().split()\n",
    "    for i in range(0,len(textList)-1):\n",
    "        bigram[tuple(textList[i:i+2])] += 1\n",
    "import operator\n",
    "sortedBigram = sorted(bigram.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182246\n"
     ]
    }
   ],
   "source": [
    "print len(bigram.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('with', 'a'), 4587),\n",
       " (('in', 'the'), 2595),\n",
       " (('of', 'the'), 2245),\n",
       " (('is', 'a'), 2056),\n",
       " (('on', 'the'), 2033)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedBigram[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "0.34361068509441478"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34361068509441478"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popularBigram = [x[0] for x in sortedBigram[:1000]]\n",
    "popularBigramToID= dict(zip(popularBigram, range(len(popularBigram))))\n",
    "popularBigramSet = set(popularBigram)\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [0]*len(popularBigram)\n",
    "    r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "    r = r.split()\n",
    "    for i in range(0, len(r)):\n",
    "        if tuple(r[i:i+2]) in popularBigram:\n",
    "            feat[popularBigramToID[tuple(r[i:i+2])]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "#With regularization\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)\n",
    "mean_squared_error(predictions, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "The MSE obtained using unigrams and bigrams is : 0.28933386918744819"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unigram = defaultdict(int)\n",
    "for text in allText:\n",
    "    textList = text.translate(None, punctuation).lower().split()\n",
    "    for w in textList:\n",
    "        unigram[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniAndBi = unigram.copy()\n",
    "uniAndBi.update(bigram)\n",
    "sortedUniAndBi = sorted(uniAndBi.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allGrams = [x[0] for x in sortedUniAndBi[:1000]]\n",
    "allGramID = dict(zip(allGrams, range(len(allGrams))))\n",
    "allGramSet = set(allGrams)\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [0] * len(allGrams)\n",
    "    text = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "    text = text.split()\n",
    "    for i in range(0,len(text)):\n",
    "        if text[i] in allGramSet:\n",
    "            feat[allGramID[text[i]]] += 1\n",
    "        if i < len(text)-1 and tuple(text[i:i+2]) in allGramSet:\n",
    "            feat[allGramID[tuple(text[i:i+2])]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28933386918744819"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [feature(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(x, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(x)\n",
    "mean_squared_error(predictions, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "The 5 unigrams/bigrams with the most positive associated weights are:\n",
    "\n",
    "'sort', 0.52168077682148783\n",
    "\n",
    "('a', 'bad'), 0.22628883434803632\n",
    "\n",
    "('of', 'these'), 0.22289001188018825\n",
    "\n",
    "('not', 'bad'), 0.21626861571067457 \n",
    "\n",
    "('the', 'best'), 0.21377221903566851\n",
    "\n",
    " The 5 unigrams/bigrams with the most negative associated weights are : \n",
    "\n",
    "('sort', 'of'), -0.64593794533391358\n",
    "\n",
    "'water', -0.27190017695088031\n",
    "\n",
    "'corn', -0.23756003904023357\n",
    "\n",
    "('the', 'background'), -0.21813867244801693\n",
    "\n",
    "'straw', -0.19975354891661662"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = zip(theta[:-1], range(1000))\n",
    "weights = map(lambda x: (allGrams[x[1]],x[0]), weights)\n",
    "weights.sort(key = lambda x:x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive:  [('sort', 0.52168077682148783), (('a', 'bad'), 0.22628883434803632), (('of', 'these'), 0.22289001188018825), (('not', 'bad'), 0.21626861571067457), (('the', 'best'), 0.21377221903566851)]\n",
      "Negative:  [(('sort', 'of'), -0.64593794533391358), ('water', -0.27190017695088031), ('corn', -0.23756003904023357), (('the', 'background'), -0.21813867244801693), ('straw', -0.19975354891661662)]\n"
     ]
    }
   ],
   "source": [
    "print 'Positive: ', weights[:5]\n",
    "print 'Negative: ', weights[-5:][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5\n",
    "The inverse document frequency and tf-idf of words 'foam', 'smell', 'banana', 'lactic', and 'tart' are :\n",
    "\n",
    "foam idf: 1.13786862069 tfidf: 2.27573724137\n",
    "\n",
    "smell idf: 0.537901618865 tfidf: 0.537901618865\n",
    "\n",
    "banana idf: 1.67778070527 tfidf: 3.35556141053\n",
    "\n",
    "lactic idf: 2.92081875395 tfidf: 5.8416375079\n",
    "\n",
    "tart idf: 1.80687540165 tfidf: 1.80687540165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf(word, text):\n",
    "    text = text.translate(None, punctuation).lower().split()\n",
    "    return text.count(word)\n",
    "def idf(word, allText):\n",
    "    hasWord = filter(lambda text: word in text.translate(None, punctuation).lower().split(), allText)\n",
    "    return np.log10(len(allText)*1./len(hasWord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foam idf: 1.13786862069 tfidf: 2.27573724137\n",
      "smell idf: 0.537901618865 tfidf: 0.537901618865\n",
      "banana idf: 1.67778070527 tfidf: 3.35556141053\n",
      "lactic idf: 2.92081875395 tfidf: 5.8416375079\n",
      "tart idf: 1.80687540165 tfidf: 1.80687540165\n"
     ]
    }
   ],
   "source": [
    "for word in ['foam', 'smell', 'banana', 'lactic', 'tart']:\n",
    "    wordidf = idf(word, allText)\n",
    "    print word, \"idf:\", wordidf, \"tfidf:\", tf(word,data[0]['review/text']) * wordidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6\n",
    "The cosine similarity between the first and the second review in terms of their tf-idf representations is : 0.106130241679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sortedUnigram = sorted(unigram.items(), key=operator.itemgetter(1), reverse=True)\n",
    "popularUnigram = [x[0] for x in sortedUnigram[:1000]]\n",
    "popularUnigramID = dict(zip(popularUnigram, range(len(popularUnigram))))\n",
    "allTextList = [text.translate(None, punctuation).lower().split() for text in allText]\n",
    "wordIdf = defaultdict(float)\n",
    "for l in allTextList:\n",
    "    for word in popularUnigram:\n",
    "        if word in l:\n",
    "            wordIdf[word] += 1\n",
    "for word in popularUnigram:\n",
    "    wordIdf[word] = np.log10(len(allText)*1./wordIdf[word])\n",
    "                             \n",
    "def tfidfFeature(text):\n",
    "    feature = [0]* 1000\n",
    "    textList = text.translate(None, punctuation).lower().split()\n",
    "    wordCount = defaultdict(int)\n",
    "    for word in textList:\n",
    "        wordCount[word] += 1\n",
    "    for i, word in enumerate(popularUnigram):\n",
    "        feature[i] = wordCount[word]*wordIdf[word]\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.106130241679\n"
     ]
    }
   ],
   "source": [
    "feature1 = tfidfFeature(data[0]['review/text'])\n",
    "feature2 = tfidfFeature(data[1]['review/text'])\n",
    "print 1 - spatial.distance.cosine(feature1, feature2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7\n",
    "beerID : 52211\n",
    "\n",
    "profileName : Dope\n",
    "\n",
    "reviewText : A: A hazy deep orange pour, almost red. Small white head that fades quickly. A little spotty lacing.\t\tS: Big pumpkin, cinnamon, ginger, nutmeg and brown sugar. Sweet. Smells like a pumpkin pie mixed with a gingerbread cookie.\t\tT: Tons of pumpkin dominates throughout. Cinnamon, ginger, nutmeg and a bit of vanilla creaminess. \t\tM: Smooth medium body. Tiny bit of drying alcohol.\t\tO: Excellent pumpkin ale. Heavy on the pumpkin but the spices don't get completely overshadowed either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beerID :  52211\n",
      "profileName :  Dope\n",
      "reviewText :  A: A hazy deep orange pour, almost red. Small white head that fades quickly. A little spotty lacing.\t\tS: Big pumpkin, cinnamon, ginger, nutmeg and brown sugar. Sweet. Smells like a pumpkin pie mixed with a gingerbread cookie.\t\tT: Tons of pumpkin dominates throughout. Cinnamon, ginger, nutmeg and a bit of vanilla creaminess. \t\tM: Smooth medium body. Tiny bit of drying alcohol.\t\tO: Excellent pumpkin ale. Heavy on the pumpkin but the spices don't get completely overshadowed either.\n"
     ]
    }
   ],
   "source": [
    "cosineDistanceList = [1 - spatial.distance.cosine(feat1, tfidfFeature(x['review/text'])) for x in data[1:]]\n",
    "result = zip(cosineDistanceList, range(len(cosineDistanceList)))\n",
    "result.sort(key = lambda x:x[0], reverse = True)\n",
    "print 'beerID : ', data[result[0][1]]['beer/beerId']\n",
    "print 'profileName : ', data[result[0][1]]['user/profileName']\n",
    "print 'reviewText : ', data[result[0][1]]['review/text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8\n",
    "The MSE obtained with the 1000-dimensional tf-idf representations is : 0.278759560078"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.278759560078\n"
     ]
    }
   ],
   "source": [
    "def feature(datum):\n",
    "    feat = [0]*len(popularUnigram)\n",
    "    r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in set(popularUnigram):\n",
    "            feat[popularUnigramID[w]] += 1\n",
    "    for i, word in enumerate(popularUnigram):\n",
    "        feat[i] *= wordIdf[word]\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "#No regularization\n",
    "#theta,residuals,rank,s = numpy.linalg.lstsq(X, y)\n",
    "\n",
    "#With regularization\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)\n",
    "mean_squared_error(predictions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
